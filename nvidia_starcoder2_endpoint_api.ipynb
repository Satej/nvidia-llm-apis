{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fbRULxFpiNm9"
      },
      "outputs": [],
      "source": [
        "API_KEY=\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "invoke_url = \"https://api.nvcf.nvidia.com/v2/nvcf/pexec/functions/6acada03-fe2f-4e4d-9e0a-e711b9fd1b59\"\n",
        "fetch_url_format = \"https://api.nvcf.nvidia.com/v2/nvcf/pexec/status/\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer {}\".format(API_KEY),\n",
        "    \"Accept\": \"application/json\",\n",
        "}\n",
        "\n",
        "payload = {\n",
        "  \"prompt\": \"X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.1) #Train a logistic regression model, predict the labels on the test set and compute the accuracy score\",\n",
        "  \"temperature\": 0.1,\n",
        "  \"top_p\": 0.7,\n",
        "  \"max_tokens\": 512,\n",
        "  \"seed\": 42,\n",
        "  \"stream\": False\n",
        "}\n",
        "\n",
        "# re-use connections\n",
        "session = requests.Session()\n",
        "\n",
        "response = session.post(invoke_url, headers=headers, json=payload)\n",
        "\n",
        "while response.status_code == 202:\n",
        "    request_id = response.headers.get(\"NVCF-REQID\")\n",
        "    fetch_url = fetch_url_format + request_id\n",
        "    response = session.get(fetch_url, headers=headers)\n",
        "\n",
        "response.raise_for_status()\n",
        "response_body = response.json()"
      ],
      "metadata": {
        "id": "lqA19pmNiXbJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The response body contains additional metadata along with completion text. Visualizing just the completion.\n",
        "print(response_body['choices'][0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h74dqcRhilOZ",
        "outputId": "edc8c9fc-ef30-4766-ce2d-8c5d2c76d96e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "# +\n",
            "# Import the necessary modules\n",
            "from sklearn.linear_model import LogisticRegression\n",
            "from sklearn.metrics import confusion_matrix, classification_report\n",
            "\n",
            "# Create training and test sets\n",
            "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\n",
            "\n",
            "# Create the classifier: logreg\n",
            "logreg = LogisticRegression()\n",
            "\n",
            "# Fit the classifier to the training data\n",
            "logreg.fit(X_train,y_train)\n",
            "\n",
            "# Predict the labels of the test set: y_pred\n",
            "y_pred = logreg.predict(X_test)\n",
            "\n",
            "# Compute and print the confusion matrix and classification report\n",
            "print(confusion_matrix(y_test, y_pred))\n",
            "print(classification_report(y_test, y_pred))\n",
            "\n",
            "# -\n",
            "\n",
            "# ### Plotting an ROC curve\n",
            "#\n",
            "#\n",
            "\n",
            "# +\n",
            "# Import necessary modules\n",
            "from sklearn.metrics import roc_curve\n",
            "\n",
            "# Compute predicted probabilities: y_pred_prob\n",
            "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
            "\n",
            "# Generate ROC curve values: fpr, tpr, thresholds\n",
            "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
            "\n",
            "# Plot ROC curve\n",
            "plt.plot([0, 1], [0, 1], 'k--')\n",
            "plt.plot(fpr, tpr)\n",
            "plt.xlabel('False Positive Rate')\n",
            "plt.ylabel('True Positive Rate')\n",
            "plt.title('ROC Curve')\n",
            "plt.show()\n",
            "\n",
            "# -\n",
            "\n",
            "# ### AUC computation\n",
            "#\n",
            "#\n",
            "\n",
            "# +\n",
            "# Import necessary modules\n",
            "from sklearn.metrics import roc_auc_score\n",
            "from sklearn.model_selection import cross_val_score\n",
            "\n",
            "# Compute predicted probabilities: y_pred_prob\n",
            "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
            "\n",
            "# Compute and print AUC score\n",
            "print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\n",
            "\n",
            "# Compute cross-validated AUC scores: cv_auc\n",
            "cv_auc = cross_val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PVn-XfEGi2a9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}